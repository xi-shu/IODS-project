# Insert chapter 4 clustering and classfication 

*Describe the work you have done this week and summarize your learning.*

- Describe your work and results clearly. 

#load dataset
```{r}

#1.create a R markdown file 
#2.load dataset
library(MASS)
data("Boston")
str(Boston)
dim(Boston)
#3.Show a graphical overview of the data 

library(magrittr)
library(corrplot)
pairs(Boston)
cor_matrix<-cor(Boston) %>% round(digits = 2)
cor_matrix
corrplot(cor_matrix, method="circle", type="upper", cl.pos="b", tl.pos="d", tl.cex = 0.6)
#4.
#Standardize the dataset and print out
boston_scaled <- scale(Boston)
summary(boston_scaled)
class(boston_scaled)
boston_scaled <- as.data.frame(boston_scaled)
#scaled crime rate
summary(boston_scaled$crim)
bins <- quantile(boston_scaled$crim)
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, labels = c("low", "med_low", "med_high", "high"))
table(crime)
#break and create the train and test sets
n <- nrow(boston_scaled)
ind <- sample(n,  size = n * 0.8)
train <- boston_scaled[ind,]
test <- boston_scaled[-ind,]
correct_classes <- test$crime
#5.
#linear discriminant analysis 
library(MASS)
lda.fit <- lda(crim ~ ., data = train)
lda.fit 
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "orange", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}
#crime rate as the target variable
classes <- as.numeric(train$crim)
#predictor variables
lda.pred <- predict(lda.fit, newdata = test)
table(correct = correct_classes, predicted =lda.pred$classes)
#Draw the LDA (bi)plot
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 1)
#6.crime catagories in test datasets,predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)
#cross tabulate the results
table(correct = correct_classes, predicted = lda.pred$classes)
#7.
#Reload the Boston dataset and standardize the dataset, then Calculate the distances between the observations.
dist_eu <- dist(Boston)
#Run k-means algorithm on the dataset
km <-kmeans(Boston, centers = 3)
#viewlization
pairs(Boston, col = km$cluster)
```